{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF_0LOEOYwX7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import sklearn.metrics as metrics\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob # global directory to access images"
      ],
      "metadata": {
        "id": "PggZn1_XZP9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=2\n",
        "IMAGE_SHAPE = [224, 224]\n",
        "batch_size=32\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "vwJOk3u-gJU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(input_shape = (224,224,3), weights = 'imagenet', include_top = False)\n",
        "for layer in vgg.layers:\n",
        " layer.trainable = False\n",
        "x = Flatten()(vgg.output)\n",
        "x = Dense(128, activation = 'relu')(x)\n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "x = Dense(num_classes, activation = 'softmax')(x)\n",
        "model = Model(inputs = vgg.input, outputs = x)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VoN4QJ1gTVt",
        "outputId": "bc8252ee-6738-406c-91f4-e5ab287f4138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trdata = ImageDataGenerator()\n",
        "train_data_gen = trdata.flow_from_directory(directory=\"/content/drive/MyDrive/NNDL/Train\",target_size=(224,224), shuffle=False, class_mode='categorical')\n",
        "tsdata = ImageDataGenerator()\n",
        "test_data_gen = tsdata.flow_from_directory(directory=\"/content/drive/MyDrive/NNDL/Test\", target_size=(224,224),shuffle=False, class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma82qDExgKd8",
        "outputId": "d14c1bec-7c9c-41c3-8bfd-472d3ea4b679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 125 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_steps_per_epoch = np.ceil(train_data_gen.samples / batch_size)\n",
        "validation_steps_per_epoch = np.ceil(test_data_gen.samples / batch_size)\n",
        "model.fit_generator(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=test_data_gen, validation_steps=validation_steps_per_epoch,epochs=epochs, verbose=1)\n",
        "print('Training Completed!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU53SRxggkyi",
        "outputId": "e9acd9ce-4d54-4f39-a974-997b3ebdc6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-b050a153b951>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=test_data_gen, validation_steps=validation_steps_per_epoch,epochs=epochs, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "4/4 [==============================] - 47s 12s/step - loss: 34.4895 - accuracy: 0.8560 - val_loss: 34.4392 - val_accuracy: 0.4000\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 28.8816 - accuracy: 0.4240 - val_loss: 5.4815 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.8216 - accuracy: 0.9520 - val_loss: 1.7920 - val_accuracy: 0.8400\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 3.8133 - accuracy: 0.8240 - val_loss: 2.5132 - val_accuracy: 0.8400\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.4195 - accuracy: 0.9680 - val_loss: 8.5235 - val_accuracy: 0.7600\n",
            "Training Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(test_data_gen, test_data_gen.samples / batch_size)\n",
        "val_preds = np.argmax(Y_pred, axis=1)\n",
        "import sklearn.metrics as metrics\n",
        "val_trues =test_data_gen.classes\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_trues, val_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsSB1MDVjliT",
        "outputId": "dc448b04-d4aa-40da-a6e0-002cc2507a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 283ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83        15\n",
            "           1       1.00      0.40      0.57        10\n",
            "\n",
            "    accuracy                           0.76        25\n",
            "   macro avg       0.86      0.70      0.70        25\n",
            "weighted avg       0.83      0.76      0.73        25\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_file=\"Model.h5\"\n",
        "tf.keras.models.save_model(model,keras_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABweGFhilBc7",
        "outputId": "c5555558-983e-4552-bb13-f038abf0b707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-981ad33596cb>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  tf.keras.models.save_model(model,keras_file)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "model = load_model('Model.h5')\n",
        "img_path = '/content/drive/MyDrive/cat.jpeg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "preds=model.predict(x)\n",
        "# create a list containing the class labels\n",
        "class_labels = ['Cat','Dog']\n",
        "# find the index of the class with maximum score\n",
        "pred = np.argmax(preds, axis=-1)\n",
        "# print the label of the class with maximum score\n",
        "print(class_labels[pred[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo1z5SGBnyBy",
        "outputId": "ce0d4534-60c9-4301-e4a1-d2cd0d7b4dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Cat\n"
          ]
        }
      ]
    }
  ]
}